#!/usr/bin/env python

"""
rigid_MLS.py: Using rigid moving-least-squares(MLS) to generate the transform
matrix parameters stored in a YAML file.
Referred to: https://github.com/Jarvis73/Moving-Least-Squares
"""

__author__ = "Jin Yu"
__copyright__ = "Copyright 2023, The RGBD-Pano Project"
__credits__ = ["Jin Yu"]
__license__ = "GPL"
__version__ = "0.0.0"
__maintainer__ = "Jin Yu"
__email__ = "547861095@qq.com"
__status__ = "Prototype"

import time

import cv2
import matplotlib.pyplot as plt
import numpy as np

USE_TORCH = False

if USE_TORCH:
    try:
        import torch  # Install PyTorch first: https://pytorch.org/get-started/locally/

        device = torch.device("cuda:0" if torch.cuda.is_available() else 'cpu')
    except ImportError as e:
        print(e)


def toy_demo():
    start_time = time.time_ns()

    image = cv2.imread("input/toy.jpg")
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    mls_map_path = 'conf/toy_grid_xd_yd_285x315.yml'

    if USE_TORCH:
        p = torch.from_numpy(np.array([
            [155, 30], [155, 125], [155, 225],
            [235, 100], [235, 160], [295, 85], [293, 180]
        ])).to(device)
        q = torch.from_numpy(np.array([
            [211, 42], [155, 125], [100, 235],
            [235, 80], [235, 140], [295, 85], [295, 180]
        ])).to(device)
        image_torch = torch.from_numpy(image).to(
            device)
        height, width, _ = image_torch.shape
        gridX = torch.arange(width, dtype=torch.int16).to(device)
        gridY = torch.arange(height, dtype=torch.int16).to(device)
        vy, vx = torch.meshgrid(gridX, gridY)
        # !!! Pay attention !!!: the shape of returned tensors are different between numpy.meshgrid and torch.meshgrid
        vy, vx = vy.transpose(0, 1), vx.transpose(0, 1)
        rigid, xmap, ymap = calculate_rigid_mls_matrix_torch(vy, vx, p, q, alpha=1)
        aug1 = torch.ones_like(image_torch).to(device)
        aug1[vx.long(), vy.long()] = image_torch[tuple(rigid)]
    else:
        p = np.array([
            [155, 30], [155, 125], [155, 225],
            [235, 100], [235, 160], [295, 85], [293, 180]
        ])
        q = np.array([
            [211, 42], [155, 125], [100, 235],
            [235, 80], [235, 140], [295, 85], [295, 180]
        ])
        height, width, _ = image.shape
        gridX = np.arange(width, dtype=np.int16)
        gridY = np.arange(height, dtype=np.int16)
        vy, vx = np.meshgrid(gridX, gridY)
        rigid, xmap, ymap = calculate_rigid_mls_matrix(vy, vx, p, q, alpha=1)
        aug1 = np.ones_like(image)
        aug1[vx, vy] = image[tuple(rigid)]

    cv_file = cv2.FileStorage(mls_map_path, cv2.FILE_STORAGE_WRITE)
    if USE_TORCH:
        xmap_np = xmap.cpu().numpy()
        ymap_np = ymap.cpu().numpy()
        cv_file.write("Xd", xmap_np)
        cv_file.write("Yd", ymap_np)
    else:
        cv_file.write("Xd", xmap)
        cv_file.write("Yd", ymap)
    cv_file.release()

    aug2 = mls_rigid_deformation(image, mls_map_path)

    whole_time = round((time.time_ns() - start_time) / 1000000)
    print('Whole processing time:', whole_time, 'ms')

    fig, ax = plt.subplots(1, 3, figsize=(8, 4))
    ax[0].imshow(image)
    ax[0].set_title("Original Image")
    if USE_TORCH:
        ax[1].imshow(aug1.cpu().numpy())
        ax[1].set_title("Rigid Deformation Torch")
    else:
        ax[1].imshow(aug1)
        ax[1].set_title("Rigid Deformation")
    ax[2].imshow(aug2)
    ax[2].set_title("Rigid Deformation II")

    for x in ax.flat:
        x.axis("off")

    plt.tight_layout(w_pad=0.1)
    plt.show()


def calculate_rigid_mls_matrix(vy, vx, p, q, alpha=1.0, eps=1e-8):
    """ Rigid MLS deformation and store the transformation map matrix in a
     dictionary

    Parameters
    ----------
    vx, vy: ndarray
        coordinate grid, generated by np.meshgrid(gridX, gridY)
    p: ndarray
        an array with size [n, 2], original control points, in (y, x) formats
    q: ndarray
        an array with size [n, 2], final control points, in (y, x) formats
    alpha: float
        parameter used by weights
    eps: float
        epsilon

    Return
    ------
        A deformed image.
        A parameter dictionary.
    """
    q = np.ascontiguousarray(q.astype(np.int16))
    p = np.ascontiguousarray(p.astype(np.int16))

    # Exchange p and q and hence we transform destination pixels to the corresponding source pixels.
    p, q = q, p

    grow = vx.shape[0]  # grid rows
    gcol = vx.shape[1]  # grid cols
    ctrls = p.shape[0]  # control points

    # Compute
    reshaped_p = p.reshape(ctrls, 2, 1, 1)  # [ctrls, 2, 1, 1]
    reshaped_v = np.vstack((vx.reshape(1, grow, gcol),
                            vy.reshape(1, grow, gcol)))  # [2, grow, gcol]

    w = 1.0 / (np.sum((reshaped_p - reshaped_v).astype(np.float32) ** 2,
                      axis=1) + eps) ** alpha  # [ctrls, grow, gcol]
    w /= np.sum(w, axis=0, keepdims=True)  # [ctrls, grow, gcol]

    pstar = np.zeros((2, grow, gcol), np.float32)
    for i in range(ctrls):
        pstar += w[i] * reshaped_p[i]  # [2, grow, gcol]

    vpstar = reshaped_v - pstar  # [2, grow, gcol]

    reshaped_vpstar = vpstar.reshape(2, 1, grow, gcol)  # [2, 1, grow, gcol]
    neg_vpstar_verti = vpstar[[1, 0], ...]  # [2, grow, gcol]
    neg_vpstar_verti[1, ...] = -neg_vpstar_verti[1, ...]
    reshaped_neg_vpstar_verti = neg_vpstar_verti.reshape(2, 1, grow,
                                                         gcol)  # [2, 1, grow, gcol]
    mul_right = np.concatenate((reshaped_vpstar, reshaped_neg_vpstar_verti),
                               axis=1)  # [2, 2, grow, gcol]
    reshaped_mul_right = mul_right.reshape(2, 2, grow,
                                           gcol)  # [2, 2, grow, gcol]

    # Calculate q
    reshaped_q = q.reshape((ctrls, 2, 1, 1))  # [ctrls, 2, 1, 1]
    qstar = np.zeros((2, grow, gcol), np.float32)
    for i in range(ctrls):
        qstar += w[i] * reshaped_q[i]  # [2, grow, gcol]

    temp = np.zeros((grow, gcol, 2), np.float32)
    for i in range(ctrls):
        phat = reshaped_p[i] - pstar  # [2, grow, gcol]
        reshaped_phat = phat.reshape(1, 2, grow, gcol)  # [1, 2, grow, gcol]
        reshaped_w = w[i].reshape(1, 1, grow, gcol)  # [1, 1, grow, gcol]
        neg_phat_verti = phat[[1, 0]]  # [2, grow, gcol]
        neg_phat_verti[1] = -neg_phat_verti[1]
        reshaped_neg_phat_verti = neg_phat_verti.reshape(1, 2, grow,
                                                         gcol)  # [1, 2, grow, gcol]
        mul_left = np.concatenate((reshaped_phat, reshaped_neg_phat_verti),
                                  axis=0)  # [2, 2, grow, gcol]

        A = np.matmul((reshaped_w * mul_left).transpose(2, 3, 0, 1),
                      reshaped_mul_right.transpose(2, 3, 0,
                                                   1))  # [grow, gcol, 2, 2]

        qhat = reshaped_q[i] - qstar  # [2, grow, gcol]
        reshaped_qhat = qhat.reshape(1, 2, grow, gcol).transpose(2, 3, 0,
                                                                 1)  # [grow, gcol, 1, 2]

        # Get final image transfomer -- 3-D array
        temp += np.matmul(reshaped_qhat, A).reshape(grow, gcol,
                                                    2)  # [grow, gcol, 2]

    temp = temp.transpose(2, 0, 1)  # [2, grow, gcol]
    normed_temp = np.linalg.norm(temp, axis=0, keepdims=True)  # [1, grow, gcol]
    normed_vpstar = np.linalg.norm(vpstar, axis=0,
                                   keepdims=True)  # [1, grow, gcol]

    transformers = temp / normed_temp * normed_vpstar + qstar  # [2, grow, gcol]
    nan_mask = normed_temp[0] == 0

    # Replace nan values by interpolated values
    nan_mask_flat = np.flatnonzero(nan_mask)
    nan_mask_anti_flat = np.flatnonzero(~nan_mask)
    transformers[0][nan_mask] = np.interp(nan_mask_flat, nan_mask_anti_flat,
                                          transformers[0][~nan_mask])
    transformers[1][nan_mask] = np.interp(nan_mask_flat, nan_mask_anti_flat,
                                          transformers[1][~nan_mask])

    # Remove the points outside the border
    transformers[transformers < 0] = 0
    transformers[0][transformers[0] > grow - 1] = 0
    transformers[1][transformers[1] > gcol - 1] = 0

    xmap = transformers[1]
    ymap = transformers[0]

    return transformers.astype(np.int16), xmap, ymap


def calculate_rigid_mls_matrix_torch(vy, vx, p, q, alpha=1.0, eps=1e-8):
    """ Rigid deformation

    Parameters
    ----------
    vx, vy: torch.Tensor
        coordinate grid, generated by torch.meshgrid(gridX, gridY)
    p: torch.Tensor
        an array with size [n, 2], original control points, in (y, x) formats
    q: torch.Tensor
        an array with size [n, 2], final control points, in (y, x) formats
    alpha: float
        parameter used by weights
    eps: float
        epsilon

    Return
    ------
        A deformed image.
    """
    device = q.device
    q = q.short()
    p = p.short()

    # Exchange p and q and hence we transform destination pixels to the corresponding source pixels.
    p, q = q, p

    grow = vx.shape[0]  # grid rows
    gcol = vx.shape[1]  # grid cols
    ctrls = p.shape[0]  # control points

    # Compute
    reshaped_p = p.reshape(ctrls, 2, 1, 1)  # [ctrls, 2, 1, 1]
    reshaped_v = torch.cat(
        (vx.reshape(1, grow, gcol), vy.reshape(1, grow, gcol)),
        dim=0)  # [2, grow, gcol]

    w = 1.0 / (torch.sum((reshaped_p - reshaped_v).float() ** 2,
                         dim=1) + eps) ** alpha  # [ctrls, grow, gcol]
    w /= torch.sum(w, dim=0, keepdim=True)  # [ctrls, grow, gcol]

    pstar = torch.zeros((2, grow, gcol), dtype=torch.float32).to(device)
    for i in range(ctrls):
        pstar += w[i] * reshaped_p[i]  # [2, grow, gcol]

    vpstar = reshaped_v - pstar  # [2, grow, gcol]
    reshaped_vpstar = vpstar.reshape(2, 1, grow, gcol)  # [2, 1, grow, gcol]
    neg_vpstar_verti = vpstar[[1, 0], ...]  # [2, grow, gcol]
    neg_vpstar_verti[1, ...] = -neg_vpstar_verti[1, ...]
    reshaped_neg_vpstar_verti = neg_vpstar_verti.reshape(2, 1, grow,
                                                         gcol)  # [2, 1, grow, gcol]
    mul_right = torch.cat((reshaped_vpstar, reshaped_neg_vpstar_verti),
                          dim=1)  # [2, 2, grow, gcol]
    reshaped_mul_right = mul_right.reshape(2, 2, grow,
                                           gcol)  # [2, 2, grow, gcol]

    # Calculate q
    reshaped_q = q.reshape((ctrls, 2, 1, 1))  # [ctrls, 2, 1, 1]
    qstar = torch.zeros((2, grow, gcol), dtype=torch.float32).to(device)
    for i in range(ctrls):
        qstar += w[i] * reshaped_q[i]  # [2, grow, gcol]

    temp = torch.zeros((grow, gcol, 2), dtype=torch.float32).to(device)
    for i in range(ctrls):
        phat = reshaped_p[i] - pstar  # [2, grow, gcol]
        reshaped_phat = phat.reshape(1, 2, grow, gcol)  # [1, 2, grow, gcol]
        reshaped_w = w[i].reshape(1, 1, grow, gcol)  # [1, 1, grow, gcol]
        neg_phat_verti = phat[[1, 0]]  # [2, grow, gcol]
        neg_phat_verti[1] = -neg_phat_verti[1]
        reshaped_neg_phat_verti = neg_phat_verti.reshape(1, 2, grow,
                                                         gcol)  # [1, 2, grow, gcol]
        mul_left = torch.cat((reshaped_phat, reshaped_neg_phat_verti),
                             dim=0)  # [2, 2, grow, gcol]

        A = torch.matmul((reshaped_w * mul_left).permute(2, 3, 0, 1),
                         reshaped_mul_right.permute(2, 3, 0,
                                                    1))  # [grow, gcol, 2, 2]

        qhat = reshaped_q[i] - qstar  # [2, grow, gcol]
        reshaped_qhat = qhat.reshape(1, 2, grow, gcol).permute(2, 3, 0,
                                                               1)  # [grow, gcol, 1, 2]

        # Get final image transfomer -- 3-D array
        temp += torch.matmul(reshaped_qhat, A).reshape(grow, gcol,
                                                       2)  # [grow, gcol, 2]

    temp = temp.permute(2, 0, 1)  # [2, grow, gcol]
    normed_temp = torch.norm(temp, dim=0, keepdim=True)  # [1, grow, gcol]
    normed_vpstar = torch.norm(vpstar, dim=0, keepdim=True)  # [1, grow, gcol]
    transformers = temp / normed_temp * normed_vpstar + qstar  # [2, grow, gcol]
    nan_mask = normed_temp[0] == 0

    # Replace nan values by interpolated values
    nan_mask_flat = torch.nonzero(nan_mask.view(-1), as_tuple=True)[0]
    nan_mask_anti_flat = torch.nonzero(~nan_mask.view(-1), as_tuple=True)[0]
    transformers[0][nan_mask] = interp(nan_mask_flat, nan_mask_anti_flat,
                                       transformers[0][~nan_mask])
    transformers[1][nan_mask] = interp(nan_mask_flat, nan_mask_anti_flat,
                                       transformers[1][~nan_mask])

    # Remove the points outside the border
    transformers[transformers < 0] = 0
    transformers[0][transformers[0] > grow - 1] = 0
    transformers[1][transformers[1] > gcol - 1] = 0

    xmap = transformers[1]
    ymap = transformers[0]

    return transformers.long(), xmap, ymap


def interp(xnew, x, y):
    """
    Linear 1D interpolation on the GPU for Pytorch.
    This function returns interpolated values of a set of 1-D functions at
    the desired query points `xnew`.
    This function is working similarly to Matlabâ„¢ or scipy functions with
    the `linear` interpolation mode on, except that it parallelises over
    any number of desired interpolation problems.
    The code will run on GPU if all the tensors provided are on a cuda
    device.
    Parameters
    ----------
    x : (N, ) or (D, N) Pytorch Tensor
        A 1-D or 2-D tensor of real values.
    y : (N,) or (D, N) Pytorch Tensor
        A 1-D or 2-D tensor of real values. The length of `y` along its
        last dimension must be the same as that of `x`
    xnew : (P,) or (D, P) Pytorch Tensor
        A 1-D or 2-D tensor of real values. `xnew` can only be 1-D if
        _both_ `x` and `y` are 1-D. Otherwise, its length along the first
        dimension must be the same as that of whichever `x` and `y` is 2-D.
    """
    # making the vectors at least 2D
    is_flat = {}
    require_grad = {}
    v = {}
    device = []
    eps = torch.finfo(y.dtype).eps
    for name, vec in {'x': x, 'y': y, 'xnew': xnew}.items():
        assert len(vec.shape) <= 2, 'interp1d: all inputs must be '\
                                    'at most 2-D.'
        if len(vec.shape) == 1:
            v[name] = vec[None, :]
        else:
            v[name] = vec
        is_flat[name] = v[name].shape[0] == 1
        require_grad[name] = vec.requires_grad
        device = list(set(device + [str(vec.device)]))
    assert len(device) == 1, 'All parameters must be on the same device.'
    device = device[0]

    # Checking for the dimensions
    assert (v['x'].shape[1] == v['y'].shape[1]
            and (
                    v['x'].shape[0] == v['y'].shape[0]
                    or v['x'].shape[0] == 1
                    or v['y'].shape[0] == 1
                )
            ), ("x and y must have the same number of columns, and either "
                "the same number of row or one of them having only one "
                "row.")

    reshaped_xnew = False
    if ((v['x'].shape[0] == 1) and (v['y'].shape[0] == 1)
        and (v['xnew'].shape[0] > 1)):
        # if there is only one row for both x and y, there is no need to
        # loop over the rows of xnew because they will all have to face the
        # same interpolation problem. We should just stack them together to
        # call interp1d and put them back in place afterwards.
        original_xnew_shape = v['xnew'].shape
        v['xnew'] = v['xnew'].contiguous().view(1, -1)
        reshaped_xnew = True

    # identify the dimensions of output and check if the one provided is ok
    D = max(v['x'].shape[0], v['xnew'].shape[0])
    shape_ynew = (D, v['xnew'].shape[-1])

    ynew = torch.zeros(*shape_ynew, device=device)

    # moving everything to the desired device in case it was not there
    # already (not handling the case things do not fit entirely, user will
    # do it if required.)
    for name in v:
        v[name] = v[name].to(device)

    # calling searchsorted on the x values.
    ind = ynew.long()

    # expanding xnew to match the number of rows of x in case only one xnew is
    # provided
    if v['xnew'].shape[0] == 1:
        v['xnew'] = v['xnew'].expand(v['x'].shape[0], -1)

    torch.searchsorted(v['x'].contiguous(),
                        v['xnew'].contiguous(), out=ind)

    # the `-1` is because searchsorted looks for the index where the values
    # must be inserted to preserve order. And we want the index of the
    # preceeding value.
    ind -= 1
    # we clamp the index, because the number of intervals is x.shape-1,
    # and the left neighbour should hence be at most number of intervals
    # -1, i.e. number of columns in x -2
    ind = torch.clamp(ind, 0, v['x'].shape[1] - 1 - 1)

    # helper function to select stuff according to the found indices.
    def sel(name):
        if is_flat[name]:
            return v[name].contiguous().view(-1)[ind]
        return torch.gather(v[name], 1, ind)

    # activating gradient storing for everything now
    enable_grad = False
    saved_inputs = []
    for name in ['x', 'y', 'xnew']:
        if require_grad[name]:
            enable_grad = True
            saved_inputs += [v[name]]
        else:
            saved_inputs += [None, ]
    # assuming x are sorted in the dimension 1, computing the slopes for
    # the segments
    is_flat['slopes'] = is_flat['x']
    # now we have found the indices of the neighbors, we start building the
    # output. Hence, we start also activating gradient tracking
    v['slopes'] = (
            (v['y'][:, 1:]-v['y'][:, :-1])
            /
            (eps + (v['x'][:, 1:]-v['x'][:, :-1]))
        )

    # now build the linear interpolation
    ynew = sel('y') + sel('slopes') * (v['xnew'] - sel('x'))

    if reshaped_xnew:
        ynew = ynew.view(original_xnew_shape)

    return ynew


def mls_rigid_deformation(img, mls_map_path):
    """ Rigid MLS deformation using the stored map matrix

        Parameters
        ----------
        img: ndarray
            source image
        mls_map_path: str
            path of yml file with 'xmap' and 'ymap' transformation matrix

        Return
        ------
            A deformed image.
        """
    fs = cv2.FileStorage(mls_map_path, cv2.FILE_STORAGE_READ)
    if fs.isOpened():
        np.set_printoptions(suppress=True)
        xmap = fs.getNode("Xd").mat()
        ymap = fs.getNode("Yd").mat()
    else:
        print("Cannot open map file: " + mls_map_path)
    img_deformed = cv2.remap(img, xmap, ymap, interpolation=cv2.INTER_LINEAR)

    return img_deformed


if __name__ == "__main__":
    toy_demo()
